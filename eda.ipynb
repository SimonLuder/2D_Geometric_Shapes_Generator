{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explorative Notebook\n",
    "\n",
    "This notebook contains exploratory visualizations that were used for the report of the MSE semester psoject \"Generative Diffusion Models for 2D Geometric Objects\". Descriptions of the visualizations are primarily found in the report itself, which is why only the rough structure of the visualizations is given in the notebook. The explorative analysis is performed on the datasets `train256`, `val256` and `test256` which are present in the data folder. They have been generated using the source code in this repository in `shape_generator.py` and `shapes.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "import textwrap\n",
    "import webcolors\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from matplotlib.pyplot import imread"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Color descriptions\n",
    "The textual color description is generated using `CSS3_HEX_TO_NAMES` from the [webcolors](https://webcolors.readthedocs.io/en/1.5/index.html) package. \n",
    "\n",
    "Description according to the documentation: \n",
    "\n",
    "\"*A dictionary whose keys are the normalized hexadecimal values of the 147 names CSS 3 colors, and whose values are the corresponding normalized names.*\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def get_color_name(requested_colour):\n",
    "        min_colours = {}\n",
    "        for key, name in webcolors.CSS3_HEX_TO_NAMES.items():\n",
    "            r_c, g_c, b_c = webcolors.hex_to_rgb(key)\n",
    "            rd = (r_c - requested_colour[0]) ** 2\n",
    "            gd = (g_c - requested_colour[1]) ** 2\n",
    "            bd = (b_c - requested_colour[2]) ** 2\n",
    "            min_colours[(rd + gd + bd)] = name\n",
    "        closest_color = min_colours[min(min_colours.keys())]\n",
    "        return closest_color\n",
    "\n",
    "def show_color_selection(requested_colour):\n",
    "\n",
    "    closest_name = get_color_name(requested_colour)\n",
    "    similar_color = dict(webcolors.CSS3_NAMES_TO_HEX)[closest_name]\n",
    "\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(4, 2))\n",
    "\n",
    "    # Check if the input is RGB array\n",
    "    if (isinstance(requested_colour, list) or isinstance(requested_colour, tuple)) and len(requested_colour) == 3:\n",
    "        requested_colour = [x/255 for x in requested_colour]  # Normalize to [0,1]\n",
    "\n",
    "    rect = patches.Rectangle((0, 0), 1, 1, facecolor=requested_colour)\n",
    "    ax[0].add_patch(rect)\n",
    "    ax[0].axis('off')\n",
    "    ax[0].set_title(\"input\")\n",
    "\n",
    "    rect = patches.Rectangle((0, 0), 1, 1, facecolor=similar_color)\n",
    "    ax[1].add_patch(rect)\n",
    "    ax[1].axis('off')\n",
    "    ax[1].set_title(f\"match\")\n",
    "    plt.suptitle(closest_name)\n",
    " \n",
    "print(\"Exaples of sampled RGB colors and the closest CSS3 color name that is used to describe the color:\")\n",
    "\n",
    "requested_colour = (244,37,20)\n",
    "show_color_selection(requested_colour)\n",
    "\n",
    "requested_colour = (104,53,140)\n",
    "show_color_selection(requested_colour)\n",
    "\n",
    "requested_colour = (133,133,0)\n",
    "show_color_selection(requested_colour)\n",
    "\n",
    "requested_colour = (200,250,0)\n",
    "show_color_selection(requested_colour)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explorative data analysis of generated data\n",
    "\n",
    "The visualisations that are used to describe the generated data sets *train_256*, *val_256* and *test_256* are created below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_train = \"data/train256/\"\n",
    "path_val = \"data/val256/\"\n",
    "path_test = \"data/test256/\"\n",
    "\n",
    "df_train = pd.read_csv(os.path.join(path_train, \"labels.csv\"))\n",
    "\n",
    "image_dir = os.path.join(path_train, \"images\")\n",
    "filenames = os.listdir(image_dir)\n",
    "\n",
    "fig, axs = plt.subplots(5, 3, figsize=(6,8))\n",
    "for i in range(5):\n",
    "    filename = filenames[random.randint(0, len(filenames))]\n",
    "    sub_df = df_train.loc[df_train[\"file\"].str.endswith(filename)].reset_index(drop=True)\n",
    "    prompt = sub_df.at[0, \"prompt\"]\n",
    "    image = imread(os.path.join(image_dir, filename))\n",
    "\n",
    "    fname = textwrap.fill(filename, 18)\n",
    "    axs[i, 0].text(0.5, 0.5, fname, size=9, ha='center', va='center')\n",
    "    axs[i, 0].axis('off')  # Hide axes on the text subplot\n",
    "\n",
    "    \n",
    "    axs[i, 1].imshow(image)\n",
    "    axs[i, 1].axis('off')  # Hide axes on the image subplot\n",
    "\n",
    "    prompt = textwrap.fill(prompt, 27)\n",
    "    axs[i, 2].text(0.6, 0.5, prompt, size=9, ha='center', va='center')\n",
    "    axs[i, 2].axis('off')  # Hide axes on the text subplot\n",
    "\n",
    "    axs[0, 0].set_title(\"label\")\n",
    "    axs[0, 1].set_title(\"image\")\n",
    "    axs[0, 2].set_title(\"prompt\")\n",
    "\n",
    "print(\"Sampled values from the train set\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nr of samples per shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_train = pd.read_csv(os.path.join(path_train, \"labels.csv\"))\n",
    "labels_val = pd.read_csv(os.path.join(path_val, \"labels.csv\"))\n",
    "labels_test = pd.read_csv(os.path.join(path_test, \"labels.csv\"))\n",
    "\n",
    "image_dir = os.path.join(path_train, \"images\")\n",
    "filenames = os.listdir(image_dir)\n",
    "\n",
    "print(\"Training set\")\n",
    "print(labels_train[\"shape_name\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nValidation set\")\n",
    "print(labels_val[\"shape_name\"].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nTest set\")\n",
    "print(labels_test[\"shape_name\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Value distributions\n",
    "\n",
    "#### Shape diameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_train[\"proportional_diameter\"] = (labels_train[\"radius\"] / labels_train[\"im_res\"]) * 2\n",
    "labels_val[\"proportional_diameter\"] = (labels_val[\"radius\"] / labels_val[\"im_res\"]) * 2\n",
    "labels_test[\"proportional_diameter\"] = (labels_test[\"radius\"] / labels_test[\"im_res\"]) * 2\n",
    "\n",
    "titles = [\"train dataset\", \"validation dataset\", \"test dataset\"]\n",
    "labels = [labels_train, labels_val, labels_test]\n",
    "fig, axs = plt.subplots(1,3, figsize=(15,3))\n",
    "\n",
    "for i, (title, label) in enumerate(zip(titles, labels)):\n",
    "    axs[i].hist(label[\"proportional_diameter\"])\n",
    "    axs[i].set_xlabel(\"Shape diameter / image width\")\n",
    "    axs[i].set_ylabel(\"count\")\n",
    "    axs[i].set_title(title)\n",
    "\n",
    "plt.suptitle(\"Distribution of shape diameters proportional to image width\", y=1.1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Position "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2,6,figsize=(15,5), gridspec_kw={'height_ratios': [1, 4], 'width_ratios': [4, 1, 4, 1, 4, 1]})\n",
    "\n",
    "labels_train[\"x_prop\"] = labels_train[\"x\"] / 256\n",
    "labels_val[\"x_prop\"] = labels_val[\"x\"] / 256\n",
    "labels_test[\"x_prop\"] = labels_test[\"x\"] / 256\n",
    "\n",
    "labels_train[\"y_prop\"] = labels_train[\"y\"] / 256\n",
    "labels_val[\"y_prop\"] = labels_val[\"y\"] / 256\n",
    "labels_test[\"y_prop\"] = labels_test[\"y\"] / 256\n",
    "\n",
    "\n",
    "axs[0, 0].hist(labels_train[\"x_prop\"])\n",
    "axs[1, 0].scatter(labels_train[\"x_prop\"], labels_train[\"y_prop\"], marker=\".\")\n",
    "axs[1, 1].hist(labels_train[\"y_prop\"], orientation=\"horizontal\")\n",
    "\n",
    "axs[0, 2].hist(labels_val[\"x_prop\"])\n",
    "axs[1, 2].scatter(labels_val[\"x_prop\"], labels_val[\"y_prop\"], marker=\".\")\n",
    "axs[1, 3].hist(labels_val[\"y_prop\"], orientation=\"horizontal\")\n",
    "\n",
    "axs[0, 4].hist(labels_test[\"x_prop\"])\n",
    "axs[1, 4].scatter(labels_test[\"x_prop\"], labels_test[\"y_prop\"], marker=\".\")\n",
    "axs[1, 5].hist(labels_test[\"y_prop\"], orientation=\"horizontal\")\n",
    "\n",
    "axs[0, 0].set_title(\"train dataset\")\n",
    "axs[0, 2].set_title(\"validation dataset\")\n",
    "axs[0, 4].set_title(\"test dataset\")\n",
    "\n",
    "\n",
    "axs[0, 1].axis(\"off\")\n",
    "axs[0, 3].axis(\"off\")\n",
    "axs[0, 5].axis(\"off\")\n",
    "\n",
    "axs[1, 0].set_xlabel(\"x\")\n",
    "axs[1, 2].set_xlabel(\"x\")\n",
    "axs[1, 4].set_xlabel(\"x\")\n",
    "\n",
    "axs[1, 0].set_ylabel(\"y\")\n",
    "axs[1, 2].set_ylabel(\"y\")\n",
    "axs[1, 4].set_ylabel(\"y\")\n",
    "\n",
    "\n",
    "plt.suptitle(\"Position of shapes in relation to image width and height\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = [\"train dataset\", \"validation dataset\", \"test dataset\"]\n",
    "labels = [labels_train, labels_val, labels_test]\n",
    "fig, axs = plt.subplots(1,3, figsize=(15,3))\n",
    "\n",
    "for i, (title, label) in enumerate(zip(titles, labels)):\n",
    "    axs[i].hist(label[\"rotation\"] * 180 / np.pi)\n",
    "    axs[i].set_xlabel(\"rotation in degrees\")\n",
    "    axs[i].set_ylabel(\"count\")\n",
    "    axs[i].set_title(title)\n",
    "\n",
    "plt.suptitle(\"Distribution of shape rotation in degrees\", y=1.1)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# plt.hist(labels_train[\"rotation\"] * 180 / np.pi)\n",
    "# plt.title(\"Distribution of shape rotation in degrees\")\n",
    "# plt.xlabel(\"rotation in degrees\")\n",
    "# plt.ylabel(\"count\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aspect Ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = [\"train dataset\", \"validation dataset\", \"test dataset\"]\n",
    "labels = [labels_train, labels_val, labels_test]\n",
    "fig, axs = plt.subplots(1,3, figsize=(15,3))\n",
    "\n",
    "for i, (title, label) in enumerate(zip(titles, labels)):\n",
    "    axs[i].hist(label[\"aspect_ratio\"], bins=5)\n",
    "    axs[i].set_xlabel(\"aspect ratio\")\n",
    "    axs[i].set_ylabel(\"count\")\n",
    "    axs[i].set_title(title)\n",
    "\n",
    "plt.suptitle(\"Distribution of the aspect ratio of shapes\", y=1.1)\n",
    "plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
